{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for the paper: \n",
    "\n",
    "## Efficient and Mobile Deep Learning Architectures for Fast Identification of BacterialStrains in Resource-Constrained Devices\n",
    "\n",
    "### Architecture: EfficientNet B2\n",
    "### Data: Augmented + Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms, models\n",
    "from pytorch_model_summary import summary\n",
    "\n",
    "# Archs not in Pytorch\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# External functions\n",
    "from scripts.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n",
      "3.8.5 (default, Jul 28 2020, 12:59:40) \n",
      "[GCC 9.3.0]\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data paths and hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters and dataset details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset details\n",
    "dataset_version = 'original' # original or augmented\n",
    "img_shape = (224,224)\n",
    "img_size = str(img_shape[0])+\"x\"+str(img_shape[1])\n",
    "\n",
    "# Root directory of dataset\n",
    "data_dir = '/home/yibbtstll/venvs/pytorch_gpu/CySDeepBacterial/Dataset/DIBaS_augmented/'\n",
    "\n",
    "train_batch_size = 32\n",
    "val_test_batch_size = 32\n",
    "feature_extract = False\n",
    "pretrained = True\n",
    "h_epochs = 10\n",
    "kfolds = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation and loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining transforms and creating dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for input data\n",
    "training_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                               [0.229, 0.224, 0.225])])\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "total_set = datasets.ImageFolder(data_dir, transform=training_transforms)\n",
    "\n",
    "# Defining folds\n",
    "splits = KFold(n_splits = kfolds, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the target classes in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "{0: 'Acinetobacter.baumanii', 1: 'Actinomyces.israeli', 2: 'Bacteroides.fragilis', 3: 'Bifidobacterium.spp', 4: 'Clostridium.perfringens', 5: 'Enterococcus.faecalis', 6: 'Enterococcus.faecium', 7: 'Escherichia.coli', 8: 'Fusobacterium', 9: 'Lactobacillus.casei', 10: 'Lactobacillus.crispatus', 11: 'Lactobacillus.delbrueckii', 12: 'Lactobacillus.gasseri', 13: 'Lactobacillus.jehnsenii', 14: 'Lactobacillus.johnsonii', 15: 'Lactobacillus.paracasei', 16: 'Lactobacillus.plantarum', 17: 'Lactobacillus.reuteri', 18: 'Lactobacillus.rhamnosus', 19: 'Lactobacillus.salivarius', 20: 'Listeria.monocytogenes', 21: 'Micrococcus.spp', 22: 'Neisseria.gonorrhoeae', 23: 'Porfyromonas.gingivalis', 24: 'Propionibacterium.acnes', 25: 'Proteus', 26: 'Pseudomonas.aeruginosa', 27: 'Staphylococcus.aureus', 28: 'Staphylococcus.epidermidis', 29: 'Staphylococcus.saprophiticus', 30: 'Streptococcus.agalactiae', 31: 'Veionella'}\n"
     ]
    }
   ],
   "source": [
    "train_labels = {value : key for (key, value) in total_set.class_to_idx.items()}\n",
    "    \n",
    "print(len(train_labels)) \n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition and inicialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freezing pre-trained parameters, finetunning the classifier to output 32 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze pretrained model parameters to avoid backpropogating through them\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        print(\"Setting grad to false.\")\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_device():\n",
    "    # Model and criterion to GPU\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    else:\n",
    "        return 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        16, 16, kernel_size=(3, 3), stride=(1, 1), groups=16, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        16, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 16, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(88, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        528, 22, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        22, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(88, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        528, 22, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        22, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(88, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        528, 22, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        22, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(88, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        528, 528, kernel_size=(5, 5), stride=[1, 1], groups=528, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        528, 22, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        22, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        528, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(120, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        720, 720, kernel_size=(5, 5), stride=(1, 1), groups=720, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        720, 30, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        30, 720, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(120, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        720, 720, kernel_size=(5, 5), stride=(1, 1), groups=720, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        720, 30, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        30, 720, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(120, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        720, 720, kernel_size=(5, 5), stride=(1, 1), groups=720, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        720, 30, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        30, 720, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(120, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        720, 720, kernel_size=(5, 5), stride=[2, 2], groups=720, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        720, 30, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        30, 720, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        720, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1248, 1248, kernel_size=(5, 5), stride=(1, 1), groups=1248, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1248, 1248, kernel_size=(5, 5), stride=(1, 1), groups=1248, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1248, 1248, kernel_size=(5, 5), stride=(1, 1), groups=1248, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1248, 1248, kernel_size=(5, 5), stride=(1, 1), groups=1248, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1248, 1248, kernel_size=(3, 3), stride=[1, 1], groups=1248, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1248, 352, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(352, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        352, 2112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(2112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2112, 2112, kernel_size=(3, 3), stride=(1, 1), groups=2112, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(2112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2112, 88, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        88, 2112, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2112, 352, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(352, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    352, 1408, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(1408, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.3, inplace=False)\n",
       "  (_fc): Linear(in_features=1408, out_features=1000, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    # Transfer Learning\n",
    "    model = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "    \n",
    "    # Mode\n",
    "    model = set_parameter_requires_grad(model, feature_extract)\n",
    "    \n",
    "    # Fine tuning\n",
    "    # Build custom classifier\n",
    "    model._fc = nn.Linear(in_features=1408,\n",
    "                        out_features=32)\n",
    "    \n",
    "    return model.to(get_device())\n",
    "\n",
    "def create_optimizer(model):\n",
    "    print(\"Running on device:\", get_device())\n",
    "    # Parameters to update\n",
    "    params_to_update = model.parameters()\n",
    "\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for param in model.parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "\n",
    "    else:\n",
    "        n_params = 0\n",
    "        for param in model.parameters():\n",
    "            if param.requires_grad == True:\n",
    "                n_params += 1\n",
    "\n",
    "\n",
    "    # Loss function and gradient descent\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().to(get_device())\n",
    "\n",
    "    optimizer = optim.Adam(params_to_update, \n",
    "                          lr=0.0001, \n",
    "                          weight_decay=0.000004)\n",
    "    \n",
    "    return criterion, model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, validation and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 0\n",
      "Samples in training: 21665\n",
      "Samples in test: 2408\n",
      "Loaded pretrained weights for efficientnet-b2\n",
      "Running on device: cuda\n",
      "\t\t Training: Epoch(0) - Loss: 1.0018, Acc: 75.9289\n",
      "\t\t Validation(0) - Loss: 0.2363, Acc: 93.4385\n",
      "\t\t Training: Epoch(1) - Loss: 0.2519, Acc: 92.4071\n",
      "\t\t Validation(1) - Loss: 0.1498, Acc: 95.4319\n",
      "\t\t Training: Epoch(2) - Loss: 0.1684, Acc: 94.8581\n",
      "\t\t Validation(2) - Loss: 0.1187, Acc: 96.3455\n",
      "\t\t Training: Epoch(3) - Loss: 0.1247, Acc: 96.1597\n",
      "\t\t Validation(3) - Loss: 0.1140, Acc: 96.2209\n",
      "\t\t Training: Epoch(4) - Loss: 0.0988, Acc: 97.0275\n",
      "\t\t Validation(4) - Loss: 0.1094, Acc: 96.3870\n",
      "\t\t Training: Epoch(5) - Loss: 0.0762, Acc: 97.5814\n",
      "\t\t Validation(5) - Loss: 0.0927, Acc: 96.8854\n",
      "\t\t Training: Epoch(6) - Loss: 0.0657, Acc: 98.0014\n",
      "\t\t Validation(6) - Loss: 0.1116, Acc: 96.5947\n",
      "\t\t Training: Epoch(7) - Loss: 0.0565, Acc: 98.2829\n",
      "\t\t Validation(7) - Loss: 0.0994, Acc: 97.2176\n",
      "\t\t Training: Epoch(8) - Loss: 0.0496, Acc: 98.4353\n",
      "\t\t Validation(8) - Loss: 0.1273, Acc: 96.5532\n",
      "\t\t Training: Epoch(9) - Loss: 0.0413, Acc: 98.7676\n",
      "\t\t Validation(9) - Loss: 0.0949, Acc: 97.0100\n",
      "Finished.\n",
      "Total time per fold: 3647.703033685684 seconds.\n",
      "Fold : 1\n",
      "Samples in training: 21665\n",
      "Samples in test: 2408\n",
      "Loaded pretrained weights for efficientnet-b2\n",
      "Running on device: cuda\n",
      "\t\t Training: Epoch(0) - Loss: 1.0144, Acc: 74.7658\n",
      "\t\t Validation(0) - Loss: 0.1854, Acc: 95.0166\n",
      "\t\t Training: Epoch(1) - Loss: 0.2580, Acc: 91.9686\n",
      "\t\t Validation(1) - Loss: 0.1380, Acc: 95.4734\n",
      "\t\t Training: Epoch(2) - Loss: 0.1690, Acc: 94.8350\n",
      "\t\t Validation(2) - Loss: 0.1028, Acc: 96.8439\n",
      "\t\t Training: Epoch(3) - Loss: 0.1274, Acc: 95.9243\n",
      "\t\t Validation(3) - Loss: 0.0959, Acc: 97.4252\n",
      "\t\t Training: Epoch(4) - Loss: 0.0946, Acc: 97.0367\n",
      "\t\t Validation(4) - Loss: 0.0929, Acc: 97.2176\n",
      "\t\t Training: Epoch(5) - Loss: 0.0806, Acc: 97.4983\n",
      "\t\t Validation(5) - Loss: 0.0980, Acc: 97.2176\n",
      "\t\t Training: Epoch(6) - Loss: 0.0678, Acc: 97.9321\n",
      "\t\t Validation(6) - Loss: 0.0838, Acc: 97.8821\n",
      "\t\t Training: Epoch(7) - Loss: 0.0529, Acc: 98.4353\n",
      "\t\t Validation(7) - Loss: 0.1045, Acc: 97.0100\n",
      "\t\t Training: Epoch(8) - Loss: 0.0508, Acc: 98.4445\n",
      "\t\t Validation(8) - Loss: 0.1041, Acc: 97.0515\n",
      "\t\t Training: Epoch(9) - Loss: 0.0458, Acc: 98.5460\n",
      "\t\t Validation(9) - Loss: 0.0816, Acc: 97.7575\n",
      "Finished.\n",
      "Total time per fold: 3218.5159904956818 seconds.\n",
      "Fold : 2\n",
      "Samples in training: 21665\n",
      "Samples in test: 2408\n",
      "Loaded pretrained weights for efficientnet-b2\n",
      "Running on device: cuda\n",
      "\t\t Training: Epoch(0) - Loss: 1.0036, Acc: 75.8689\n",
      "\t\t Validation(0) - Loss: 0.2266, Acc: 93.1063\n",
      "\t\t Training: Epoch(1) - Loss: 0.2510, Acc: 92.4210\n",
      "\t\t Validation(1) - Loss: 0.1404, Acc: 95.7641\n",
      "\t\t Training: Epoch(2) - Loss: 0.1678, Acc: 94.8211\n",
      "\t\t Validation(2) - Loss: 0.1213, Acc: 96.2209\n",
      "\t\t Training: Epoch(3) - Loss: 0.1192, Acc: 96.2289\n",
      "\t\t Validation(3) - Loss: 0.1162, Acc: 96.4701\n",
      "\t\t Training: Epoch(4) - Loss: 0.0924, Acc: 96.9952\n",
      "\t\t Validation(4) - Loss: 0.0925, Acc: 97.3422\n",
      "\t\t Training: Epoch(5) - Loss: 0.0731, Acc: 97.7429\n",
      "\t\t Validation(5) - Loss: 0.1213, Acc: 96.1379\n",
      "\t\t Training: Epoch(6) - Loss: 0.0659, Acc: 98.0799\n",
      "\t\t Validation(6) - Loss: 0.1095, Acc: 96.9684\n",
      "\t\t Training: Epoch(7) - Loss: 0.0551, Acc: 98.2876\n",
      "\t\t Validation(7) - Loss: 0.1003, Acc: 97.3837\n",
      "\t\t Training: Epoch(8) - Loss: 0.0499, Acc: 98.4353\n",
      "\t\t Validation(8) - Loss: 0.1267, Acc: 96.5116\n",
      "\t\t Training: Epoch(9) - Loss: 0.0420, Acc: 98.7491\n",
      "\t\t Validation(9) - Loss: 0.1197, Acc: 96.5947\n",
      "Finished.\n",
      "Total time per fold: 3017.6834766864777 seconds.\n",
      "Fold : 3\n",
      "Samples in training: 21666\n",
      "Samples in test: 2407\n",
      "Loaded pretrained weights for efficientnet-b2\n",
      "Running on device: cuda\n",
      "\t\t Training: Epoch(0) - Loss: 1.0037, Acc: 75.5192\n",
      "\t\t Validation(0) - Loss: 0.1956, Acc: 94.3083\n",
      "\t\t Training: Epoch(1) - Loss: 0.2559, Acc: 92.0890\n",
      "\t\t Validation(1) - Loss: 0.1219, Acc: 96.2609\n",
      "\t\t Training: Epoch(2) - Loss: 0.1705, Acc: 94.8029\n",
      "\t\t Validation(2) - Loss: 0.0954, Acc: 96.7179\n",
      "\t\t Training: Epoch(3) - Loss: 0.1268, Acc: 96.0122\n",
      "\t\t Validation(3) - Loss: 0.0969, Acc: 96.8841\n",
      "\t\t Training: Epoch(4) - Loss: 0.0983, Acc: 96.8061\n",
      "\t\t Validation(4) - Loss: 0.0991, Acc: 96.6764\n",
      "\t\t Training: Epoch(5) - Loss: 0.0813, Acc: 97.4245\n",
      "\t\t Validation(5) - Loss: 0.0840, Acc: 97.2995\n",
      "\t\t Training: Epoch(6) - Loss: 0.0652, Acc: 97.9784\n",
      "\t\t Validation(6) - Loss: 0.0864, Acc: 97.3411\n",
      "\t\t Training: Epoch(7) - Loss: 0.0544, Acc: 98.2415\n",
      "\t\t Validation(7) - Loss: 0.0965, Acc: 97.2165\n",
      "\t\t Training: Epoch(8) - Loss: 0.0498, Acc: 98.4169\n",
      "\t\t Validation(8) - Loss: 0.0952, Acc: 96.8841\n",
      "\t\t Training: Epoch(9) - Loss: 0.0415, Acc: 98.6569\n",
      "\t\t Validation(9) - Loss: 0.0943, Acc: 97.4242\n",
      "Finished.\n",
      "Total time per fold: 3022.203007221222 seconds.\n",
      "Fold : 4\n",
      "Samples in training: 21666\n",
      "Samples in test: 2407\n",
      "Loaded pretrained weights for efficientnet-b2\n",
      "Running on device: cuda\n",
      "\t\t Training: Epoch(0) - Loss: 1.0073, Acc: 75.8977\n",
      "\t\t Validation(0) - Loss: 0.2166, Acc: 93.3112\n",
      "\t\t Training: Epoch(1) - Loss: 0.2615, Acc: 92.1675\n",
      "\t\t Validation(1) - Loss: 0.1435, Acc: 95.3054\n",
      "\t\t Training: Epoch(2) - Loss: 0.1708, Acc: 94.7891\n",
      "\t\t Validation(2) - Loss: 0.1323, Acc: 95.2638\n",
      "\t\t Training: Epoch(3) - Loss: 0.1302, Acc: 96.0306\n",
      "\t\t Validation(3) - Loss: 0.1096, Acc: 96.5933\n",
      "\t\t Training: Epoch(4) - Loss: 0.1023, Acc: 96.7230\n",
      "\t\t Validation(4) - Loss: 0.1072, Acc: 96.5933\n",
      "\t\t Training: Epoch(5) - Loss: 0.0819, Acc: 97.4061\n",
      "\t\t Validation(5) - Loss: 0.0919, Acc: 97.0503\n",
      "\t\t Training: Epoch(6) - Loss: 0.0666, Acc: 97.9230\n",
      "\t\t Validation(6) - Loss: 0.1213, Acc: 96.6348\n",
      "\t\t Training: Epoch(7) - Loss: 0.0640, Acc: 97.9784\n",
      "\t\t Validation(7) - Loss: 0.0848, Acc: 97.0503\n",
      "\t\t Training: Epoch(8) - Loss: 0.0498, Acc: 98.5230\n",
      "\t\t Validation(8) - Loss: 0.0857, Acc: 97.5488\n",
      "\t\t Training: Epoch(9) - Loss: 0.0437, Acc: 98.7215\n",
      "\t\t Validation(9) - Loss: 0.1093, Acc: 97.0503\n",
      "Finished.\n",
      "Total time per fold: 3031.8725185394287 seconds.\n",
      "Fold : 5\n",
      "Samples in training: 21666\n",
      "Samples in test: 2407\n",
      "Loaded pretrained weights for efficientnet-b2\n",
      "Running on device: cuda\n",
      "\t\t Training: Epoch(0) - Loss: 1.0196, Acc: 75.4177\n",
      "\t\t Validation(0) - Loss: 0.2296, Acc: 92.6880\n",
      "\t\t Training: Epoch(1) - Loss: 0.2533, Acc: 92.4444\n",
      "\t\t Validation(1) - Loss: 0.1490, Acc: 95.1392\n",
      "\t\t Training: Epoch(2) - Loss: 0.1703, Acc: 94.6968\n",
      "\t\t Validation(2) - Loss: 0.1330, Acc: 95.5546\n",
      "\t\t Training: Epoch(3) - Loss: 0.1261, Acc: 96.0814\n",
      "\t\t Validation(3) - Loss: 0.1047, Acc: 96.4686\n",
      "\t\t Training: Epoch(4) - Loss: 0.1048, Acc: 96.7137\n",
      "\t\t Validation(4) - Loss: 0.1292, Acc: 95.8455\n",
      "\t\t Training: Epoch(5) - Loss: 0.0803, Acc: 97.5307\n",
      "\t\t Validation(5) - Loss: 0.1081, Acc: 96.7179\n",
      "\t\t Training: Epoch(6) - Loss: 0.0656, Acc: 98.0292\n",
      "\t\t Validation(6) - Loss: 0.1057, Acc: 96.7595\n",
      "\t\t Training: Epoch(7) - Loss: 0.0601, Acc: 98.1215\n",
      "\t\t Validation(7) - Loss: 0.0918, Acc: 97.0087\n",
      "\t\t Training: Epoch(8) - Loss: 0.0486, Acc: 98.4723\n",
      "\t\t Validation(8) - Loss: 0.0978, Acc: 96.9672\n",
      "\t\t Training: Epoch(9) - Loss: 0.0405, Acc: 98.7307\n",
      "\t\t Validation(9) - Loss: 0.0954, Acc: 97.0918\n",
      "Finished.\n",
      "Total time per fold: 3033.8671736717224 seconds.\n",
      "Fold : 6\n",
      "Samples in training: 21666\n",
      "Samples in test: 2407\n",
      "Loaded pretrained weights for efficientnet-b2\n",
      "Running on device: cuda\n",
      "\t\t Training: Epoch(0) - Loss: 1.0085, Acc: 75.8839\n",
      "\t\t Validation(0) - Loss: 0.2120, Acc: 93.4358\n",
      "\t\t Training: Epoch(1) - Loss: 0.2646, Acc: 92.1951\n",
      "\t\t Validation(1) - Loss: 0.1276, Acc: 96.2194\n",
      "\t\t Training: Epoch(2) - Loss: 0.1632, Acc: 95.0798\n",
      "\t\t Validation(2) - Loss: 0.1113, Acc: 96.5102\n",
      "\t\t Training: Epoch(3) - Loss: 0.1232, Acc: 96.1368\n",
      "\t\t Validation(3) - Loss: 0.1193, Acc: 96.1363\n",
      "\t\t Training: Epoch(4) - Loss: 0.0988, Acc: 96.8799\n",
      "\t\t Validation(4) - Loss: 0.1104, Acc: 96.2609\n",
      "\t\t Training: Epoch(5) - Loss: 0.0777, Acc: 97.6045\n",
      "\t\t Validation(5) - Loss: 0.0818, Acc: 97.3826\n",
      "\t\t Training: Epoch(6) - Loss: 0.0635, Acc: 98.0107\n",
      "\t\t Validation(6) - Loss: 0.1195, Acc: 96.3855\n",
      "\t\t Training: Epoch(7) - Loss: 0.0567, Acc: 98.2184\n",
      "\t\t Validation(7) - Loss: 0.0952, Acc: 97.0087\n",
      "\t\t Training: Epoch(8) - Loss: 0.0495, Acc: 98.4538\n",
      "\t\t Validation(8) - Loss: 0.1153, Acc: 96.3855\n",
      "\t\t Training: Epoch(9) - Loss: 0.0406, Acc: 98.7677\n",
      "\t\t Validation(9) - Loss: 0.1030, Acc: 96.7595\n",
      "Finished.\n",
      "Total time per fold: 3034.587844133377 seconds.\n",
      "Fold : 7\n",
      "Samples in training: 21666\n",
      "Samples in test: 2407\n",
      "Loaded pretrained weights for efficientnet-b2\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t Training: Epoch(0) - Loss: 1.0054, Acc: 75.7962\n",
      "\t\t Validation(0) - Loss: 0.2126, Acc: 93.7266\n",
      "\t\t Training: Epoch(1) - Loss: 0.2545, Acc: 92.1213\n",
      "\t\t Validation(1) - Loss: 0.1385, Acc: 95.8039\n",
      "\t\t Training: Epoch(2) - Loss: 0.1691, Acc: 94.8629\n",
      "\t\t Validation(2) - Loss: 0.1213, Acc: 95.9285\n",
      "\t\t Training: Epoch(3) - Loss: 0.1236, Acc: 96.1414\n",
      "\t\t Validation(3) - Loss: 0.1051, Acc: 96.4686\n",
      "\t\t Training: Epoch(4) - Loss: 0.0993, Acc: 96.8891\n",
      "\t\t Validation(4) - Loss: 0.1035, Acc: 96.4271\n",
      "\t\t Training: Epoch(5) - Loss: 0.0853, Acc: 97.2538\n",
      "\t\t Validation(5) - Loss: 0.1075, Acc: 96.3025\n",
      "\t\t Training: Epoch(6) - Loss: 0.0685, Acc: 97.8630\n",
      "\t\t Validation(6) - Loss: 0.1122, Acc: 96.5517\n",
      "\t\t Training: Epoch(7) - Loss: 0.0563, Acc: 98.2507\n",
      "\t\t Validation(7) - Loss: 0.0898, Acc: 97.2165\n",
      "\t\t Training: Epoch(8) - Loss: 0.0489, Acc: 98.5046\n",
      "\t\t Validation(8) - Loss: 0.1253, Acc: 96.4271\n",
      "\t\t Training: Epoch(9) - Loss: 0.0426, Acc: 98.7492\n",
      "\t\t Validation(9) - Loss: 0.1151, Acc: 96.7179\n",
      "Finished.\n",
      "Total time per fold: 3042.099109888077 seconds.\n",
      "Fold : 8\n",
      "Samples in training: 21666\n",
      "Samples in test: 2407\n",
      "Loaded pretrained weights for efficientnet-b2\n",
      "Running on device: cuda\n",
      "\t\t Training: Epoch(0) - Loss: 1.0190, Acc: 75.0300\n",
      "\t\t Validation(0) - Loss: 0.2102, Acc: 93.6435\n",
      "\t\t Training: Epoch(1) - Loss: 0.2562, Acc: 92.1351\n",
      "\t\t Validation(1) - Loss: 0.1208, Acc: 96.5933\n",
      "\t\t Training: Epoch(2) - Loss: 0.1705, Acc: 94.8583\n",
      "\t\t Validation(2) - Loss: 0.1120, Acc: 96.6764\n",
      "\t\t Training: Epoch(3) - Loss: 0.1250, Acc: 96.2476\n",
      "\t\t Validation(3) - Loss: 0.1004, Acc: 96.7179\n",
      "\t\t Training: Epoch(4) - Loss: 0.0981, Acc: 97.0276\n",
      "\t\t Validation(4) - Loss: 0.0922, Acc: 96.8841\n",
      "\t\t Training: Epoch(5) - Loss: 0.0787, Acc: 97.5861\n",
      "\t\t Validation(5) - Loss: 0.0918, Acc: 97.1749\n",
      "\t\t Training: Epoch(6) - Loss: 0.0650, Acc: 98.0292\n",
      "\t\t Validation(6) - Loss: 0.0925, Acc: 96.9672\n",
      "\t\t Training: Epoch(7) - Loss: 0.0587, Acc: 98.1953\n",
      "\t\t Validation(7) - Loss: 0.0856, Acc: 97.1749\n",
      "\t\t Training: Epoch(8) - Loss: 0.0464, Acc: 98.6477\n",
      "\t\t Validation(8) - Loss: 0.1105, Acc: 96.8010\n",
      "\t\t Training: Epoch(9) - Loss: 0.0425, Acc: 98.6938\n",
      "\t\t Validation(9) - Loss: 0.1006, Acc: 97.2165\n",
      "Finished.\n",
      "Total time per fold: 3194.6498873233795 seconds.\n",
      "Fold : 9\n",
      "Samples in training: 21666\n",
      "Samples in test: 2407\n",
      "Loaded pretrained weights for efficientnet-b2\n",
      "Running on device: cuda\n",
      "\t\t Training: Epoch(0) - Loss: 1.0198, Acc: 75.1823\n",
      "\t\t Validation(0) - Loss: 0.1937, Acc: 94.0174\n",
      "\t\t Training: Epoch(1) - Loss: 0.2681, Acc: 91.7797\n",
      "\t\t Validation(1) - Loss: 0.1097, Acc: 96.5933\n",
      "\t\t Training: Epoch(2) - Loss: 0.1738, Acc: 94.5768\n",
      "\t\t Validation(2) - Loss: 0.0925, Acc: 96.7595\n",
      "\t\t Training: Epoch(3) - Loss: 0.1281, Acc: 96.0491\n",
      "\t\t Validation(3) - Loss: 0.0767, Acc: 97.4657\n",
      "\t\t Training: Epoch(4) - Loss: 0.1028, Acc: 96.8799\n",
      "\t\t Validation(4) - Loss: 0.0764, Acc: 97.5488\n",
      "\t\t Training: Epoch(5) - Loss: 0.0841, Acc: 97.3507\n",
      "\t\t Validation(5) - Loss: 0.0887, Acc: 97.1334\n",
      "\t\t Training: Epoch(6) - Loss: 0.0718, Acc: 97.7015\n",
      "\t\t Validation(6) - Loss: 0.0715, Acc: 97.6735\n",
      "\t\t Training: Epoch(7) - Loss: 0.0557, Acc: 98.2646\n",
      "\t\t Validation(7) - Loss: 0.0888, Acc: 97.3826\n",
      "\t\t Training: Epoch(8) - Loss: 0.0509, Acc: 98.4076\n",
      "\t\t Validation(8) - Loss: 0.0806, Acc: 97.7981\n",
      "\t\t Training: Epoch(9) - Loss: 0.0434, Acc: 98.5876\n",
      "\t\t Validation(9) - Loss: 0.0799, Acc: 97.8812\n",
      "Finished.\n",
      "Total time per fold: 3171.457065820694 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Variables to store fold scores\n",
    "train_acc = []\n",
    "test_top1_acc = []\n",
    "test_top5_acc = []\n",
    "test_precision = []\n",
    "test_recall = []\n",
    "test_f1 = []\n",
    "times = []\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(splits.split(total_set)):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    print('Fold : {}'.format(fold))\n",
    "    \n",
    "    # Train and val samplers\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    print(\"Samples in training:\", len(train_sampler))\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    print(\"Samples in test:\", len(valid_sampler))\n",
    "    \n",
    "    # Train and val loaders\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "                      total_set, batch_size=train_batch_size, sampler=train_sampler)\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "                      total_set, batch_size=1, sampler=valid_sampler)\n",
    "    \n",
    "    device = get_device()\n",
    "    \n",
    "    criterion, model, optimizer = create_optimizer(load_model())\n",
    "    \n",
    "    # Training\n",
    "    for epoch in range(h_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        trunning_corrects = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += (preds == labels).sum()\n",
    "            trunning_corrects += preds.size(0)\n",
    "            \n",
    "\n",
    "        epoch_loss = running_loss / trunning_corrects\n",
    "        epoch_acc = (running_corrects.double()*100) / trunning_corrects\n",
    "        train_acc.append(epoch_acc.item())\n",
    "        \n",
    "        print('\\t\\t Training: Epoch({}) - Loss: {:.4f}, Acc: {:.4f}'.format(epoch, epoch_loss, epoch_acc))\n",
    "        \n",
    "        # Validation\n",
    "        \n",
    "        model.eval()  \n",
    "        \n",
    "        vrunning_loss = 0.0\n",
    "        vrunning_corrects = 0\n",
    "        num_samples = 0\n",
    "        \n",
    "        for data, labels in valid_loader:\n",
    "            \n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(data)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "            vrunning_loss += loss.item() * data.size(0)\n",
    "            vrunning_corrects += (preds == labels).sum()\n",
    "            num_samples += preds.size(0)\n",
    "            \n",
    "        vepoch_loss = vrunning_loss/num_samples\n",
    "        vepoch_acc = (vrunning_corrects.double() * 100)/num_samples\n",
    "        \n",
    "        print('\\t\\t Validation({}) - Loss: {:.4f}, Acc: {:.4f}'.format(epoch, vepoch_loss, vepoch_acc))\n",
    "    \n",
    "    # Calculating and appending scores to this fold\n",
    "    model.class_to_idx = total_set.class_to_idx\n",
    "    scores = get_scores(model, valid_loader)\n",
    "    \n",
    "    test_top1_acc.append(scores[0])\n",
    "    test_top5_acc.append(scores[1])\n",
    "    test_precision.append(scores[2])\n",
    "    test_recall.append(scores[3])\n",
    "    test_f1.append(scores[4])\n",
    "    \n",
    "    time_fold = time.time() - start_time\n",
    "    times.append(time_fold)\n",
    "    print(\"Total time per fold: %s seconds.\" %(time_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy average:  0.9463705366296952\n",
      "Top-1 test accuracy average:  0.9715033809197152\n",
      "Top-5 test accuracy average:  0.9970506151079286\n",
      "Weighted Precision test accuracy average:  0.9723711915246716\n",
      "Weighted Recall test accuracy average:  0.9715033809197152\n",
      "Weighted F1 test accuracy average:  0.9715796652012862\n",
      "Average time per fold (seconds): 3141.4639107465746\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy average: \", np.mean(train_acc) / 100)\n",
    "print(\"Top-1 test accuracy average: \", np.mean(test_top1_acc))\n",
    "print(\"Top-5 test accuracy average: \", np.mean(test_top5_acc))\n",
    "print(\"Weighted Precision test accuracy average: \", np.mean(test_precision))\n",
    "print(\"Weighted Recall test accuracy average: \", np.mean(test_recall))\n",
    "print(\"Weighted F1 test accuracy average: \", np.mean(test_f1))\n",
    "print(\"Average time per fold (seconds):\", np.mean(times))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
