{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for the paper: \n",
    "\n",
    "## Efficient and Mobile Deep Learning Architectures for Fast Identification of BacterialStrains in Resource-Constrained Devices\n",
    "\n",
    "### Architecture: EfficientNet B0\n",
    "### Data: Original + Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms, models\n",
    "from pytorch_model_summary import summary\n",
    "\n",
    "# Archs not in Pytorch\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# External functions\n",
    "from scripts.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n",
      "3.8.5 (default, Jul 28 2020, 12:59:40) \n",
      "[GCC 9.3.0]\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data paths and hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters and dataset details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset details\n",
    "dataset_version = 'original' # original or augmented\n",
    "img_shape = (224,224)\n",
    "img_size = str(img_shape[0])+\"x\"+str(img_shape[1])\n",
    "\n",
    "# Root directory of dataset\n",
    "data_dir = '/home/yibbtstll/venvs/pytorch_gpu/CySDeepBacterial/Dataset/DIBaS/'\n",
    "\n",
    "train_batch_size = 32\n",
    "val_test_batch_size = 32\n",
    "feature_extract = False\n",
    "pretrained = True\n",
    "h_epochs = 15\n",
    "kfolds = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation and loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining transforms and creating dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for input data\n",
    "training_transforms = transforms.Compose([transforms.Resize((224,224), Image.LANCZOS),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                               [0.229, 0.224, 0.225])])\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "total_set = datasets.ImageFolder(data_dir, transform=training_transforms)\n",
    "\n",
    "# Defining folds\n",
    "splits = KFold(n_splits = kfolds, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the target classes in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "{0: 'Acinetobacter.baumanii', 1: 'Actinomyces.israeli', 2: 'Bacteroides.fragilis', 3: 'Bifidobacterium.spp', 4: 'Clostridium.perfringens', 5: 'Enterococcus.faecalis', 6: 'Enterococcus.faecium', 7: 'Escherichia.coli', 8: 'Fusobacterium', 9: 'Lactobacillus.casei', 10: 'Lactobacillus.crispatus', 11: 'Lactobacillus.delbrueckii', 12: 'Lactobacillus.gasseri', 13: 'Lactobacillus.jehnsenii', 14: 'Lactobacillus.johnsonii', 15: 'Lactobacillus.paracasei', 16: 'Lactobacillus.plantarum', 17: 'Lactobacillus.reuteri', 18: 'Lactobacillus.rhamnosus', 19: 'Lactobacillus.salivarius', 20: 'Listeria.monocytogenes', 21: 'Micrococcus.spp', 22: 'Neisseria.gonorrhoeae', 23: 'Porfyromonas.gingivalis', 24: 'Propionibacterium.acnes', 25: 'Proteus', 26: 'Pseudomonas.aeruginosa', 27: 'Staphylococcus.aureus', 28: 'Staphylococcus.epidermidis', 29: 'Staphylococcus.saprophiticus', 30: 'Streptococcus.agalactiae', 31: 'Veionella'}\n"
     ]
    }
   ],
   "source": [
    "train_labels = {value : key for (key, value) in total_set.class_to_idx.items()}\n",
    "    \n",
    "print(len(train_labels)) \n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition and inicialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freezing pre-trained parameters, finetunning the classifier to output 32 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze pretrained model parameters to avoid backpropogating through them\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        print(\"Setting grad to false.\")\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_device():\n",
    "    # Model and criterion to GPU\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    else:\n",
    "        return 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EfficientNet.from_name('efficientnet-b0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    # Transfer Learning\n",
    "    model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "    \n",
    "    # Mode\n",
    "    model = set_parameter_requires_grad(model, feature_extract)\n",
    "    \n",
    "    # Fine tuning\n",
    "    # Build custom classifier\n",
    "    model._fc = nn.Linear(in_features=1280,\n",
    "                        out_features=32)\n",
    "    return model\n",
    "\n",
    "def create_optimizer(model):\n",
    "    # Parameters to update\n",
    "    params_to_update = model.parameters()\n",
    "\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for param in model.parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "\n",
    "    else:\n",
    "        n_params = 0\n",
    "        for param in model.parameters():\n",
    "            if param.requires_grad == True:\n",
    "                n_params += 1\n",
    "\n",
    "\n",
    "    # Loss function and gradient descent\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.Adam(params_to_update, \n",
    "                          lr=0.001, \n",
    "                          weight_decay=0.000004)\n",
    "    \n",
    "    return criterion.to(get_device()), model.to(get_device()), optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, validation and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 0\n",
      "Samples in training: 602\n",
      "Samples in test: 67\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "\t\t Training: Epoch(0) - Loss: 2.2111, Acc: 49.8339\n",
      "\t\t Validation(0) - Loss: 3.1885, Acc: 17.9104\n",
      "\t\t Training: Epoch(1) - Loss: 0.5192, Acc: 85.5482\n",
      "\t\t Validation(1) - Loss: 3.2964, Acc: 13.4328\n",
      "\t\t Training: Epoch(2) - Loss: 0.2709, Acc: 92.3588\n",
      "\t\t Validation(2) - Loss: 3.4652, Acc: 26.8657\n",
      "\t\t Training: Epoch(3) - Loss: 0.2271, Acc: 92.1927\n",
      "\t\t Validation(3) - Loss: 1.8388, Acc: 53.7313\n",
      "\t\t Training: Epoch(4) - Loss: 0.2147, Acc: 93.8538\n",
      "\t\t Validation(4) - Loss: 1.2688, Acc: 59.7015\n",
      "\t\t Training: Epoch(5) - Loss: 0.1398, Acc: 97.0100\n",
      "\t\t Validation(5) - Loss: 0.7419, Acc: 76.1194\n",
      "\t\t Training: Epoch(6) - Loss: 0.1435, Acc: 95.5150\n",
      "\t\t Validation(6) - Loss: 1.1701, Acc: 74.6269\n",
      "\t\t Training: Epoch(7) - Loss: 0.0743, Acc: 98.0066\n",
      "\t\t Validation(7) - Loss: 0.7241, Acc: 83.5821\n",
      "\t\t Training: Epoch(8) - Loss: 0.0730, Acc: 97.6744\n",
      "\t\t Validation(8) - Loss: 0.4762, Acc: 89.5522\n",
      "\t\t Training: Epoch(9) - Loss: 0.0732, Acc: 98.0066\n",
      "\t\t Validation(9) - Loss: 0.3912, Acc: 89.5522\n",
      "\t\t Training: Epoch(10) - Loss: 0.0772, Acc: 98.5050\n",
      "\t\t Validation(10) - Loss: 0.6438, Acc: 83.5821\n",
      "\t\t Training: Epoch(11) - Loss: 0.0757, Acc: 97.8405\n",
      "\t\t Validation(11) - Loss: 0.2896, Acc: 91.0448\n",
      "\t\t Training: Epoch(12) - Loss: 0.0405, Acc: 99.1694\n",
      "\t\t Validation(12) - Loss: 0.4584, Acc: 89.5522\n",
      "\t\t Training: Epoch(13) - Loss: 0.0600, Acc: 98.5050\n",
      "\t\t Validation(13) - Loss: 0.4757, Acc: 88.0597\n",
      "\t\t Training: Epoch(14) - Loss: 0.0358, Acc: 98.6711\n",
      "\t\t Validation(14) - Loss: 0.4379, Acc: 89.5522\n",
      "Finished.\n",
      "Top-1 Accuracy:  0.8955223880597015\n",
      "Top-5 Accuracy:  1.0\n",
      "Weighted Precision 0.877363184079602\n",
      "Weighted Recall 0.8955223880597015\n",
      "Weighted F1 0.8775171760246386\n",
      "Total time per fold: 400.79250264167786 seconds.\n",
      "Fold : 1\n",
      "Samples in training: 602\n",
      "Samples in test: 67\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "\t\t Training: Epoch(0) - Loss: 2.1294, Acc: 56.4784\n",
      "\t\t Validation(0) - Loss: 2.8508, Acc: 19.4030\n",
      "\t\t Training: Epoch(1) - Loss: 0.4995, Acc: 86.7110\n",
      "\t\t Validation(1) - Loss: 2.2102, Acc: 38.8060\n",
      "\t\t Training: Epoch(2) - Loss: 0.3010, Acc: 90.5316\n",
      "\t\t Validation(2) - Loss: 1.7336, Acc: 61.1940\n",
      "\t\t Training: Epoch(3) - Loss: 0.1705, Acc: 94.6844\n",
      "\t\t Validation(3) - Loss: 1.4759, Acc: 62.6866\n",
      "\t\t Training: Epoch(4) - Loss: 0.2492, Acc: 92.0266\n",
      "\t\t Validation(4) - Loss: 0.7976, Acc: 76.1194\n",
      "\t\t Training: Epoch(5) - Loss: 0.2271, Acc: 93.6877\n",
      "\t\t Validation(5) - Loss: 1.3956, Acc: 59.7015\n",
      "\t\t Training: Epoch(6) - Loss: 0.1437, Acc: 95.5150\n",
      "\t\t Validation(6) - Loss: 2.7454, Acc: 56.7164\n",
      "\t\t Training: Epoch(7) - Loss: 0.1322, Acc: 95.8472\n",
      "\t\t Validation(7) - Loss: 1.0142, Acc: 77.6119\n",
      "\t\t Training: Epoch(8) - Loss: 0.1583, Acc: 95.3488\n",
      "\t\t Validation(8) - Loss: 0.8961, Acc: 76.1194\n",
      "\t\t Training: Epoch(9) - Loss: 0.0889, Acc: 97.1761\n",
      "\t\t Validation(9) - Loss: 0.2971, Acc: 92.5373\n",
      "\t\t Training: Epoch(10) - Loss: 0.0615, Acc: 98.1728\n",
      "\t\t Validation(10) - Loss: 0.5395, Acc: 85.0746\n",
      "\t\t Training: Epoch(11) - Loss: 0.0982, Acc: 96.5116\n",
      "\t\t Validation(11) - Loss: 0.2582, Acc: 94.0299\n",
      "\t\t Training: Epoch(12) - Loss: 0.0605, Acc: 98.3389\n",
      "\t\t Validation(12) - Loss: 0.6750, Acc: 82.0896\n",
      "\t\t Training: Epoch(13) - Loss: 0.0919, Acc: 97.3422\n",
      "\t\t Validation(13) - Loss: 0.3987, Acc: 91.0448\n",
      "\t\t Training: Epoch(14) - Loss: 0.0968, Acc: 97.8405\n",
      "\t\t Validation(14) - Loss: 0.3624, Acc: 94.0299\n",
      "Finished.\n",
      "Top-1 Accuracy:  0.9402985074626866\n",
      "Top-5 Accuracy:  1.0\n",
      "Weighted Precision 0.9395522388059702\n",
      "Weighted Recall 0.9402985074626866\n",
      "Weighted F1 0.9312097521052743\n",
      "Total time per fold: 396.61745524406433 seconds.\n",
      "Fold : 2\n",
      "Samples in training: 602\n",
      "Samples in test: 67\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "\t\t Training: Epoch(0) - Loss: 2.0617, Acc: 55.4817\n",
      "\t\t Validation(0) - Loss: 2.9718, Acc: 17.9104\n",
      "\t\t Training: Epoch(1) - Loss: 0.5046, Acc: 88.7043\n",
      "\t\t Validation(1) - Loss: 2.1568, Acc: 41.7910\n",
      "\t\t Training: Epoch(2) - Loss: 0.3110, Acc: 90.1993\n",
      "\t\t Validation(2) - Loss: 1.4803, Acc: 53.7313\n",
      "\t\t Training: Epoch(3) - Loss: 0.2234, Acc: 94.0199\n",
      "\t\t Validation(3) - Loss: 1.4480, Acc: 59.7015\n",
      "\t\t Training: Epoch(4) - Loss: 0.1353, Acc: 96.1794\n",
      "\t\t Validation(4) - Loss: 1.2412, Acc: 68.6567\n",
      "\t\t Training: Epoch(5) - Loss: 0.1591, Acc: 95.1827\n",
      "\t\t Validation(5) - Loss: 1.0243, Acc: 68.6567\n",
      "\t\t Training: Epoch(6) - Loss: 0.0963, Acc: 96.6777\n",
      "\t\t Validation(6) - Loss: 0.8058, Acc: 76.1194\n",
      "\t\t Training: Epoch(7) - Loss: 0.0886, Acc: 98.3389\n",
      "\t\t Validation(7) - Loss: 0.7993, Acc: 76.1194\n",
      "\t\t Training: Epoch(8) - Loss: 0.1088, Acc: 97.1761\n",
      "\t\t Validation(8) - Loss: 0.5510, Acc: 86.5672\n",
      "\t\t Training: Epoch(9) - Loss: 0.1575, Acc: 95.1827\n",
      "\t\t Validation(9) - Loss: 0.6556, Acc: 83.5821\n",
      "\t\t Training: Epoch(10) - Loss: 0.0679, Acc: 98.5050\n",
      "\t\t Validation(10) - Loss: 1.1508, Acc: 77.6119\n",
      "\t\t Training: Epoch(11) - Loss: 0.1291, Acc: 96.3455\n",
      "\t\t Validation(11) - Loss: 0.7867, Acc: 82.0896\n",
      "\t\t Training: Epoch(12) - Loss: 0.0663, Acc: 97.8405\n",
      "\t\t Validation(12) - Loss: 0.9419, Acc: 79.1045\n",
      "\t\t Training: Epoch(13) - Loss: 0.1245, Acc: 96.5116\n",
      "\t\t Validation(13) - Loss: 0.4133, Acc: 91.0448\n",
      "\t\t Training: Epoch(14) - Loss: 0.0885, Acc: 97.1761\n",
      "\t\t Validation(14) - Loss: 0.5474, Acc: 85.0746\n",
      "Finished.\n",
      "Top-1 Accuracy:  0.8507462686567164\n",
      "Top-5 Accuracy:  1.0\n",
      "Weighted Precision 0.8171641791044776\n",
      "Weighted Recall 0.8507462686567164\n",
      "Weighted F1 0.8179815209665955\n",
      "Total time per fold: 402.7529888153076 seconds.\n",
      "Fold : 3\n",
      "Samples in training: 602\n",
      "Samples in test: 67\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "\t\t Training: Epoch(0) - Loss: 2.0440, Acc: 55.1495\n",
      "\t\t Validation(0) - Loss: 2.8159, Acc: 28.3582\n",
      "\t\t Training: Epoch(1) - Loss: 0.4650, Acc: 87.3754\n",
      "\t\t Validation(1) - Loss: 3.3654, Acc: 25.3731\n",
      "\t\t Training: Epoch(2) - Loss: 0.3881, Acc: 87.8738\n",
      "\t\t Validation(2) - Loss: 3.1161, Acc: 25.3731\n",
      "\t\t Training: Epoch(3) - Loss: 0.2194, Acc: 93.1894\n",
      "\t\t Validation(3) - Loss: 2.9582, Acc: 32.8358\n",
      "\t\t Training: Epoch(4) - Loss: 0.1204, Acc: 97.0100\n",
      "\t\t Validation(4) - Loss: 2.2698, Acc: 52.2388\n",
      "\t\t Training: Epoch(5) - Loss: 0.1128, Acc: 96.8439\n",
      "\t\t Validation(5) - Loss: 2.0955, Acc: 52.2388\n",
      "\t\t Training: Epoch(6) - Loss: 0.1419, Acc: 96.0133\n",
      "\t\t Validation(6) - Loss: 1.1894, Acc: 73.1343\n",
      "\t\t Training: Epoch(7) - Loss: 0.1718, Acc: 95.0166\n",
      "\t\t Validation(7) - Loss: 1.2129, Acc: 68.6567\n",
      "\t\t Training: Epoch(8) - Loss: 0.1217, Acc: 96.6777\n",
      "\t\t Validation(8) - Loss: 0.5125, Acc: 89.5522\n",
      "\t\t Training: Epoch(9) - Loss: 0.1130, Acc: 96.3455\n",
      "\t\t Validation(9) - Loss: 1.2758, Acc: 71.6418\n",
      "\t\t Training: Epoch(10) - Loss: 0.1225, Acc: 96.3455\n",
      "\t\t Validation(10) - Loss: 0.4715, Acc: 82.0896\n",
      "\t\t Training: Epoch(11) - Loss: 0.1082, Acc: 96.6777\n",
      "\t\t Validation(11) - Loss: 1.1898, Acc: 79.1045\n",
      "\t\t Training: Epoch(12) - Loss: 0.0865, Acc: 97.8405\n",
      "\t\t Validation(12) - Loss: 0.6187, Acc: 83.5821\n",
      "\t\t Training: Epoch(13) - Loss: 0.1099, Acc: 96.0133\n",
      "\t\t Validation(13) - Loss: 0.5172, Acc: 82.0896\n",
      "\t\t Training: Epoch(14) - Loss: 0.0697, Acc: 98.3389\n",
      "\t\t Validation(14) - Loss: 0.4391, Acc: 89.5522\n",
      "Finished.\n",
      "Top-1 Accuracy:  0.8955223880597015\n",
      "Top-5 Accuracy:  0.9850746268656716\n",
      "Weighted Precision 0.9184079601990051\n",
      "Weighted Recall 0.8955223880597015\n",
      "Weighted F1 0.8919838039241024\n",
      "Total time per fold: 398.2178132534027 seconds.\n",
      "Fold : 4\n",
      "Samples in training: 602\n",
      "Samples in test: 67\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "\t\t Training: Epoch(0) - Loss: 2.0889, Acc: 54.3189\n",
      "\t\t Validation(0) - Loss: 2.5960, Acc: 22.3881\n",
      "\t\t Training: Epoch(1) - Loss: 0.4019, Acc: 90.3654\n",
      "\t\t Validation(1) - Loss: 3.1327, Acc: 20.8955\n",
      "\t\t Training: Epoch(2) - Loss: 0.3376, Acc: 89.8671\n",
      "\t\t Validation(2) - Loss: 3.5199, Acc: 17.9104\n",
      "\t\t Training: Epoch(3) - Loss: 0.1762, Acc: 94.3522\n",
      "\t\t Validation(3) - Loss: 1.6310, Acc: 55.2239\n",
      "\t\t Training: Epoch(4) - Loss: 0.1367, Acc: 95.8472\n",
      "\t\t Validation(4) - Loss: 1.0295, Acc: 65.6716\n",
      "\t\t Training: Epoch(5) - Loss: 0.1381, Acc: 96.8439\n",
      "\t\t Validation(5) - Loss: 1.4293, Acc: 68.6567\n",
      "\t\t Training: Epoch(6) - Loss: 0.1794, Acc: 95.8472\n",
      "\t\t Validation(6) - Loss: 1.9281, Acc: 56.7164\n",
      "\t\t Training: Epoch(7) - Loss: 0.1397, Acc: 95.6811\n",
      "\t\t Validation(7) - Loss: 0.7139, Acc: 80.5970\n",
      "\t\t Training: Epoch(8) - Loss: 0.0855, Acc: 97.5083\n",
      "\t\t Validation(8) - Loss: 0.7185, Acc: 80.5970\n",
      "\t\t Training: Epoch(9) - Loss: 0.0768, Acc: 97.8405\n",
      "\t\t Validation(9) - Loss: 1.5088, Acc: 70.1493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t Training: Epoch(10) - Loss: 0.0946, Acc: 97.0100\n",
      "\t\t Validation(10) - Loss: 0.6325, Acc: 85.0746\n",
      "\t\t Training: Epoch(11) - Loss: 0.1309, Acc: 97.3422\n",
      "\t\t Validation(11) - Loss: 0.6329, Acc: 85.0746\n",
      "\t\t Training: Epoch(12) - Loss: 0.0829, Acc: 98.1728\n",
      "\t\t Validation(12) - Loss: 0.4727, Acc: 83.5821\n",
      "\t\t Training: Epoch(13) - Loss: 0.0879, Acc: 97.1761\n",
      "\t\t Validation(13) - Loss: 1.2176, Acc: 80.5970\n",
      "\t\t Training: Epoch(14) - Loss: 0.0540, Acc: 98.8372\n",
      "\t\t Validation(14) - Loss: 0.4548, Acc: 86.5672\n",
      "Finished.\n",
      "Top-1 Accuracy:  0.8656716417910447\n",
      "Top-5 Accuracy:  0.9850746268656716\n",
      "Weighted Precision 0.8614427860696516\n",
      "Weighted Recall 0.8656716417910447\n",
      "Weighted F1 0.8507818052594172\n",
      "Total time per fold: 399.85715508461 seconds.\n",
      "Fold : 5\n",
      "Samples in training: 602\n",
      "Samples in test: 67\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "\t\t Training: Epoch(0) - Loss: 2.1667, Acc: 52.1595\n",
      "\t\t Validation(0) - Loss: 2.7846, Acc: 20.8955\n",
      "\t\t Training: Epoch(1) - Loss: 0.5305, Acc: 86.5449\n",
      "\t\t Validation(1) - Loss: 2.5458, Acc: 32.8358\n",
      "\t\t Training: Epoch(2) - Loss: 0.2474, Acc: 93.5216\n",
      "\t\t Validation(2) - Loss: 2.0987, Acc: 49.2537\n",
      "\t\t Training: Epoch(3) - Loss: 0.1619, Acc: 95.6811\n",
      "\t\t Validation(3) - Loss: 2.4682, Acc: 47.7612\n",
      "\t\t Training: Epoch(4) - Loss: 0.2650, Acc: 93.0233\n",
      "\t\t Validation(4) - Loss: 1.8334, Acc: 68.6567\n",
      "\t\t Training: Epoch(5) - Loss: 0.1963, Acc: 93.3555\n",
      "\t\t Validation(5) - Loss: 1.6885, Acc: 58.2090\n",
      "\t\t Training: Epoch(6) - Loss: 0.1556, Acc: 96.0133\n",
      "\t\t Validation(6) - Loss: 1.4755, Acc: 65.6716\n",
      "\t\t Training: Epoch(7) - Loss: 0.1062, Acc: 97.3422\n",
      "\t\t Validation(7) - Loss: 0.8995, Acc: 71.6418\n",
      "\t\t Training: Epoch(8) - Loss: 0.0740, Acc: 97.5083\n",
      "\t\t Validation(8) - Loss: 0.9411, Acc: 82.0896\n",
      "\t\t Training: Epoch(9) - Loss: 0.0490, Acc: 98.5050\n",
      "\t\t Validation(9) - Loss: 0.9544, Acc: 85.0746\n",
      "\t\t Training: Epoch(10) - Loss: 0.1836, Acc: 94.8505\n",
      "\t\t Validation(10) - Loss: 1.8102, Acc: 61.1940\n",
      "\t\t Training: Epoch(11) - Loss: 0.1015, Acc: 96.6777\n",
      "\t\t Validation(11) - Loss: 1.4411, Acc: 65.6716\n",
      "\t\t Training: Epoch(12) - Loss: 0.1333, Acc: 96.5116\n",
      "\t\t Validation(12) - Loss: 0.2993, Acc: 89.5522\n",
      "\t\t Training: Epoch(13) - Loss: 0.0559, Acc: 98.3389\n",
      "\t\t Validation(13) - Loss: 0.9039, Acc: 80.5970\n",
      "\t\t Training: Epoch(14) - Loss: 0.0684, Acc: 98.1728\n",
      "\t\t Validation(14) - Loss: 0.7012, Acc: 85.0746\n",
      "Finished.\n",
      "Top-1 Accuracy:  0.8507462686567164\n",
      "Top-5 Accuracy:  0.9850746268656716\n",
      "Weighted Precision 0.8830845771144278\n",
      "Weighted Recall 0.8507462686567164\n",
      "Weighted F1 0.8461975835110163\n",
      "Total time per fold: 401.52808475494385 seconds.\n",
      "Fold : 6\n",
      "Samples in training: 602\n",
      "Samples in test: 67\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "\t\t Training: Epoch(0) - Loss: 2.2047, Acc: 53.1561\n",
      "\t\t Validation(0) - Loss: 2.6504, Acc: 20.8955\n",
      "\t\t Training: Epoch(1) - Loss: 0.4874, Acc: 89.0365\n",
      "\t\t Validation(1) - Loss: 3.1482, Acc: 26.8657\n",
      "\t\t Training: Epoch(2) - Loss: 0.3178, Acc: 91.1960\n",
      "\t\t Validation(2) - Loss: 2.2916, Acc: 40.2985\n",
      "\t\t Training: Epoch(3) - Loss: 0.1657, Acc: 94.8505\n",
      "\t\t Validation(3) - Loss: 2.3367, Acc: 49.2537\n",
      "\t\t Training: Epoch(4) - Loss: 0.1795, Acc: 94.6844\n",
      "\t\t Validation(4) - Loss: 1.9896, Acc: 49.2537\n",
      "\t\t Training: Epoch(5) - Loss: 0.1278, Acc: 96.8439\n",
      "\t\t Validation(5) - Loss: 2.1403, Acc: 53.7313\n",
      "\t\t Training: Epoch(6) - Loss: 0.1174, Acc: 97.0100\n",
      "\t\t Validation(6) - Loss: 1.2762, Acc: 70.1493\n",
      "\t\t Training: Epoch(7) - Loss: 0.1053, Acc: 96.6777\n",
      "\t\t Validation(7) - Loss: 1.2149, Acc: 77.6119\n",
      "\t\t Training: Epoch(8) - Loss: 0.1232, Acc: 97.3422\n",
      "\t\t Validation(8) - Loss: 0.6470, Acc: 82.0896\n",
      "\t\t Training: Epoch(9) - Loss: 0.0801, Acc: 97.5083\n",
      "\t\t Validation(9) - Loss: 0.7542, Acc: 82.0896\n",
      "\t\t Training: Epoch(10) - Loss: 0.0802, Acc: 96.5116\n",
      "\t\t Validation(10) - Loss: 1.0618, Acc: 76.1194\n",
      "\t\t Training: Epoch(11) - Loss: 0.0908, Acc: 97.6744\n",
      "\t\t Validation(11) - Loss: 0.6825, Acc: 83.5821\n",
      "\t\t Training: Epoch(12) - Loss: 0.0490, Acc: 98.6711\n",
      "\t\t Validation(12) - Loss: 1.7064, Acc: 53.7313\n",
      "\t\t Training: Epoch(13) - Loss: 0.0716, Acc: 97.8405\n",
      "\t\t Validation(13) - Loss: 0.5425, Acc: 88.0597\n",
      "\t\t Training: Epoch(14) - Loss: 0.0457, Acc: 99.1694\n",
      "\t\t Validation(14) - Loss: 0.8449, Acc: 82.0896\n",
      "Finished.\n",
      "Top-1 Accuracy:  0.8208955223880597\n",
      "Top-5 Accuracy:  0.9850746268656716\n",
      "Weighted Precision 0.8624733475479744\n",
      "Weighted Recall 0.8208955223880597\n",
      "Weighted F1 0.8130710085933968\n",
      "Total time per fold: 402.9565417766571 seconds.\n",
      "Fold : 7\n",
      "Samples in training: 602\n",
      "Samples in test: 67\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "\t\t Training: Epoch(0) - Loss: 2.1979, Acc: 51.8272\n",
      "\t\t Validation(0) - Loss: 3.5028, Acc: 2.9851\n",
      "\t\t Training: Epoch(1) - Loss: 0.4944, Acc: 89.3688\n",
      "\t\t Validation(1) - Loss: 3.3899, Acc: 25.3731\n",
      "\t\t Training: Epoch(2) - Loss: 0.2304, Acc: 92.6910\n",
      "\t\t Validation(2) - Loss: 3.0161, Acc: 34.3284\n",
      "\t\t Training: Epoch(3) - Loss: 0.2351, Acc: 93.5216\n",
      "\t\t Validation(3) - Loss: 2.2665, Acc: 44.7761\n",
      "\t\t Training: Epoch(4) - Loss: 0.1881, Acc: 94.8505\n",
      "\t\t Validation(4) - Loss: 1.1929, Acc: 68.6567\n",
      "\t\t Training: Epoch(5) - Loss: 0.2143, Acc: 93.6877\n",
      "\t\t Validation(5) - Loss: 1.8027, Acc: 68.6567\n",
      "\t\t Training: Epoch(6) - Loss: 0.1411, Acc: 95.5150\n",
      "\t\t Validation(6) - Loss: 0.8020, Acc: 76.1194\n",
      "\t\t Training: Epoch(7) - Loss: 0.1207, Acc: 96.5116\n",
      "\t\t Validation(7) - Loss: 0.6113, Acc: 77.6119\n",
      "\t\t Training: Epoch(8) - Loss: 0.0972, Acc: 97.6744\n",
      "\t\t Validation(8) - Loss: 0.8847, Acc: 74.6269\n",
      "\t\t Training: Epoch(9) - Loss: 0.0834, Acc: 97.0100\n",
      "\t\t Validation(9) - Loss: 0.2646, Acc: 91.0448\n",
      "\t\t Training: Epoch(10) - Loss: 0.0492, Acc: 99.1694\n",
      "\t\t Validation(10) - Loss: 0.5185, Acc: 85.0746\n",
      "\t\t Training: Epoch(11) - Loss: 0.0616, Acc: 98.1728\n",
      "\t\t Validation(11) - Loss: 0.1231, Acc: 97.0149\n",
      "\t\t Training: Epoch(12) - Loss: 0.0575, Acc: 98.3389\n",
      "\t\t Validation(12) - Loss: 0.4661, Acc: 89.5522\n",
      "\t\t Training: Epoch(13) - Loss: 0.0563, Acc: 98.5050\n",
      "\t\t Validation(13) - Loss: 0.1823, Acc: 95.5224\n",
      "\t\t Training: Epoch(14) - Loss: 0.0523, Acc: 98.8372\n",
      "\t\t Validation(14) - Loss: 0.1361, Acc: 97.0149\n",
      "Finished.\n",
      "Top-1 Accuracy:  0.9701492537313433\n",
      "Top-5 Accuracy:  1.0\n",
      "Weighted Precision 0.9788557213930348\n",
      "Weighted Recall 0.9701492537313433\n",
      "Weighted F1 0.9705756929637526\n",
      "Total time per fold: 404.1865723133087 seconds.\n",
      "Fold : 8\n",
      "Samples in training: 602\n",
      "Samples in test: 67\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "\t\t Training: Epoch(0) - Loss: 2.1331, Acc: 53.8206\n",
      "\t\t Validation(0) - Loss: 2.6248, Acc: 25.3731\n",
      "\t\t Training: Epoch(1) - Loss: 0.5127, Acc: 85.7143\n",
      "\t\t Validation(1) - Loss: 2.2606, Acc: 41.7910\n",
      "\t\t Training: Epoch(2) - Loss: 0.2930, Acc: 90.8638\n",
      "\t\t Validation(2) - Loss: 1.6029, Acc: 53.7313\n",
      "\t\t Training: Epoch(3) - Loss: 0.1133, Acc: 98.0066\n",
      "\t\t Validation(3) - Loss: 1.2986, Acc: 65.6716\n",
      "\t\t Training: Epoch(4) - Loss: 0.1685, Acc: 94.6844\n",
      "\t\t Validation(4) - Loss: 1.1395, Acc: 68.6567\n",
      "\t\t Training: Epoch(5) - Loss: 0.1466, Acc: 95.8472\n",
      "\t\t Validation(5) - Loss: 2.1430, Acc: 62.6866\n",
      "\t\t Training: Epoch(6) - Loss: 0.1426, Acc: 95.5150\n",
      "\t\t Validation(6) - Loss: 1.1113, Acc: 67.1642\n",
      "\t\t Training: Epoch(7) - Loss: 0.1386, Acc: 95.6811\n",
      "\t\t Validation(7) - Loss: 0.8811, Acc: 73.1343\n",
      "\t\t Training: Epoch(8) - Loss: 0.1052, Acc: 97.5083\n",
      "\t\t Validation(8) - Loss: 1.3353, Acc: 65.6716\n",
      "\t\t Training: Epoch(9) - Loss: 0.0531, Acc: 98.5050\n",
      "\t\t Validation(9) - Loss: 0.5859, Acc: 85.0746\n",
      "\t\t Training: Epoch(10) - Loss: 0.0853, Acc: 97.0100\n",
      "\t\t Validation(10) - Loss: 0.2855, Acc: 92.5373\n",
      "\t\t Training: Epoch(11) - Loss: 0.0777, Acc: 98.1728\n",
      "\t\t Validation(11) - Loss: 1.0115, Acc: 73.1343\n",
      "\t\t Training: Epoch(12) - Loss: 0.0762, Acc: 97.3422\n",
      "\t\t Validation(12) - Loss: 0.6012, Acc: 83.5821\n",
      "\t\t Training: Epoch(13) - Loss: 0.0767, Acc: 98.0066\n",
      "\t\t Validation(13) - Loss: 0.3857, Acc: 89.5522\n",
      "\t\t Training: Epoch(14) - Loss: 0.0953, Acc: 97.0100\n",
      "\t\t Validation(14) - Loss: 0.2743, Acc: 94.0299\n",
      "Finished.\n",
      "Top-1 Accuracy:  0.9402985074626866\n",
      "Top-5 Accuracy:  0.9850746268656716\n",
      "Weighted Precision 0.9669154228855721\n",
      "Weighted Recall 0.9402985074626866\n",
      "Weighted F1 0.9460317460317461\n",
      "Total time per fold: 391.59421253204346 seconds.\n",
      "Fold : 9\n",
      "Samples in training: 603\n",
      "Samples in test: 66\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "\t\t Training: Epoch(0) - Loss: 2.0971, Acc: 56.5506\n",
      "\t\t Validation(0) - Loss: 2.3916, Acc: 27.2727\n",
      "\t\t Training: Epoch(1) - Loss: 0.5066, Acc: 86.2355\n",
      "\t\t Validation(1) - Loss: 3.2959, Acc: 21.2121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t Training: Epoch(2) - Loss: 0.2544, Acc: 93.3665\n",
      "\t\t Validation(2) - Loss: 3.0639, Acc: 27.2727\n",
      "\t\t Training: Epoch(3) - Loss: 0.2468, Acc: 91.8740\n",
      "\t\t Validation(3) - Loss: 2.5022, Acc: 37.8788\n",
      "\t\t Training: Epoch(4) - Loss: 0.1913, Acc: 95.5224\n",
      "\t\t Validation(4) - Loss: 1.9315, Acc: 51.5152\n",
      "\t\t Training: Epoch(5) - Loss: 0.0910, Acc: 97.5124\n",
      "\t\t Validation(5) - Loss: 2.1657, Acc: 54.5455\n",
      "\t\t Training: Epoch(6) - Loss: 0.0878, Acc: 97.0149\n",
      "\t\t Validation(6) - Loss: 1.1792, Acc: 71.2121\n",
      "\t\t Training: Epoch(7) - Loss: 0.0808, Acc: 97.8441\n",
      "\t\t Validation(7) - Loss: 1.3743, Acc: 72.7273\n",
      "\t\t Training: Epoch(8) - Loss: 0.0897, Acc: 98.0100\n",
      "\t\t Validation(8) - Loss: 0.4742, Acc: 89.3939\n",
      "\t\t Training: Epoch(9) - Loss: 0.0783, Acc: 98.0100\n",
      "\t\t Validation(9) - Loss: 0.9297, Acc: 78.7879\n",
      "\t\t Training: Epoch(10) - Loss: 0.1187, Acc: 96.8491\n",
      "\t\t Validation(10) - Loss: 0.7763, Acc: 80.3030\n",
      "\t\t Training: Epoch(11) - Loss: 0.1491, Acc: 95.5224\n",
      "\t\t Validation(11) - Loss: 0.8020, Acc: 81.8182\n",
      "\t\t Training: Epoch(12) - Loss: 0.1296, Acc: 96.1857\n",
      "\t\t Validation(12) - Loss: 0.8803, Acc: 81.8182\n",
      "\t\t Training: Epoch(13) - Loss: 0.0797, Acc: 97.3466\n",
      "\t\t Validation(13) - Loss: 0.6097, Acc: 89.3939\n",
      "\t\t Training: Epoch(14) - Loss: 0.0601, Acc: 98.5075\n",
      "\t\t Validation(14) - Loss: 0.5839, Acc: 90.9091\n",
      "Finished.\n",
      "Top-1 Accuracy:  0.9090909090909091\n",
      "Top-5 Accuracy:  0.9696969696969697\n",
      "Weighted Precision 0.9671717171717171\n",
      "Weighted Recall 0.9090909090909091\n",
      "Weighted F1 0.9280991735537188\n",
      "Total time per fold: 389.8298614025116 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Variables to store fold scores\n",
    "train_acc = []\n",
    "test_top1_acc = []\n",
    "test_top5_acc = []\n",
    "test_precision = []\n",
    "test_recall = []\n",
    "test_f1 = []\n",
    "times = []\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(splits.split(total_set)):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    print('Fold : {}'.format(fold))\n",
    "    \n",
    "    # Train and val samplers\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    print(\"Samples in training:\", len(train_sampler))\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    print(\"Samples in test:\", len(valid_sampler))\n",
    "    \n",
    "    # Train and val loaders\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "                      total_set, batch_size=train_batch_size, sampler=train_sampler)\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "                      total_set, batch_size=1, sampler=valid_sampler)\n",
    "    \n",
    "    device = get_device()\n",
    "    \n",
    "    criterion, model, optimizer = create_optimizer(load_model())\n",
    "    \n",
    "    # Training\n",
    "    for epoch in range(h_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        trunning_corrects = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += (preds == labels).sum()\n",
    "            trunning_corrects += preds.size(0)\n",
    "            \n",
    "\n",
    "        epoch_loss = running_loss / trunning_corrects\n",
    "        epoch_acc = (running_corrects.double()*100) / trunning_corrects\n",
    "        train_acc.append(epoch_acc.item())\n",
    "        \n",
    "        print('\\t\\t Training: Epoch({}) - Loss: {:.4f}, Acc: {:.4f}'.format(epoch, epoch_loss, epoch_acc))\n",
    "        \n",
    "        # Validation\n",
    "        \n",
    "        model.eval()  \n",
    "        \n",
    "        vrunning_loss = 0.0\n",
    "        vrunning_corrects = 0\n",
    "        num_samples = 0\n",
    "        \n",
    "        for data, labels in valid_loader:\n",
    "            \n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(data)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "            vrunning_loss += loss.item() * data.size(0)\n",
    "            vrunning_corrects += (preds == labels).sum()\n",
    "            num_samples += preds.size(0)\n",
    "            \n",
    "        vepoch_loss = vrunning_loss/num_samples\n",
    "        vepoch_acc = (vrunning_corrects.double() * 100)/num_samples\n",
    "        \n",
    "        print('\\t\\t Validation({}) - Loss: {:.4f}, Acc: {:.4f}'.format(epoch, vepoch_loss, vepoch_acc))\n",
    "    \n",
    "    # Calculating and appending scores to this fold\n",
    "    scores = get_scores(model, valid_loader, total_set)\n",
    "    \n",
    "    test_top1_acc.append(scores[0])\n",
    "    test_top5_acc.append(scores[1])\n",
    "    test_precision.append(scores[2])\n",
    "    test_recall.append(scores[3])\n",
    "    test_f1.append(scores[4])\n",
    "    \n",
    "    time_fold = time.time() - start_time\n",
    "    times.append(time_fold)\n",
    "    print(\"Total time per fold: %s seconds.\" %(time_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy average:  0.928549684210913\n",
      "Top-1 test accuracy average:  0.8938941655359566\n",
      "Top-5 test accuracy average:  0.989507010402533\n",
      "Weighted Precision test accuracy average:  0.9072431134371431\n",
      "Weighted Recall test accuracy average:  0.8938941655359566\n",
      "Weighted F1 test accuracy average:  0.8873449262933658\n",
      "Average time per fold (seconds): 398.8333187818527\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy average: \", np.mean(train_acc) / 100)\n",
    "print(\"Top-1 test accuracy average: \", np.mean(test_top1_acc))\n",
    "print(\"Top-5 test accuracy average: \", np.mean(test_top5_acc))\n",
    "print(\"Weighted Precision test accuracy average: \", np.mean(test_precision))\n",
    "print(\"Weighted Recall test accuracy average: \", np.mean(test_recall))\n",
    "print(\"Weighted F1 test accuracy average: \", np.mean(test_f1))\n",
    "print(\"Average time per fold (seconds):\", np.mean(times))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
